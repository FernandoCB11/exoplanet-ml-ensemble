from sklearn.model_selection import train_test_split
from datetime import datetime
import multiprocessing
import os
import sys
import joblib
import numpy as np
import tensorflow as tf
from pandas import DataFrame
from pandas import Series

sys.path.append(os.path.normpath(os.path.join(os.path.dirname(os.path.abspath(__file__)),'..','includes/exoplanet-ml-master/exoplanet-ml/')))  # noqa E501
from astronet.data import preprocess  # noqa E402


class AstroNetPreprocessing:

    """
    Wrapper class for Shallue, C. J., & Vanderburg, A. (2018) AstroNet model.
    AstroNet code at https://github.com/google-research/exoplanet-ml.

    This wrapper class defines some standard interfaces to be used by our
    Stacking ensemble model and encapsulates the preprocessing steps of the
    original preprocess.py module.

    We've enhanced the original AstroNet preprocessing by adding a cache
    feature where, in scenarios of multiple runs over the same dataset, i.e.
    k-fold cross validation or repeated holdouts, a lightcurve already
    treated with the preprocessing steps of Vanderburg & Johnson (2014) and
    separeted into the local and global views is cached in a local file,
    removing the need to rerun the whole preprocessing steps to generate the
    tfrecord file for this run's subset of the original dataset.

    Attributes
    ----------
    tfrecord_dir: str
        Path to where the tfrecord files as stored.
    data_dir: str
        Base directory where the lightcurve files are stored.
    num_worker_processes: int
        Number of worker processess to be spawned in the parallel processing of
        the input files.
    cache_dir: str
        Cache directory for preprocessed lightcurves.
    """
    def __init__(self, base_dir: str, data_dir: str, cache_dir: str):  # noqa E501
        """
        Parameters
        ----------
        base_dir: str
            Base directory where the tfrecord and model dirs will be created.
        cache_dir: str
            Cache directory for preprocessed lightcurves.
        """

        self.tfrecord_dir = f"{base_dir}_{datetime.now().strftime('%Y%m%d%H%M%S')}_tfrecord/"  # noqa E501
        self.data_dir = data_dir
        self.cache_dir = cache_dir
        self.num_worker_processes = 3

    def _process_tce(self, tce: Series, kepler_dir: str):
        """
        Reimplementation of the original _process_tce function of the
        preprocessing.py module, incorporating the caching mechanism
        and generating a clear python interface to be used during the
        ensemble processing.

        Parameters
        ----------
        tce: Series
            DataFrame row as a Series containing the TCE information.
        kepler_dir: str
            Directory where the lightcurve files are. Kept for compatibility.

        Returns
        -------
        ex: tf.train.Example
            Tensorflow example of this TCE.
        """
        ex = None
        file = os.path.join(self.cache_dir, str(tce['kepid']))
        # checks for the cache file
        if os.path.isfile(file):
            ex = joblib.load(file)
        else:
            all_time, all_flux = preprocess.read_light_curve(tce['kepid'], kepler_dir)  # noqa E501
            time, flux = preprocess.process_light_curve(all_time, all_flux)
            ex = preprocess.generate_example_for_tce(time, flux, tce)
            joblib.dump(ex, file)
        return ex

    def _process_file_shard(self, tce_table: DataFrame, file_name: str, kepler_dir: str):  # noqa E501
        """
        Port of the original _process_file_shard function of the
        preprocessing.py module for it to be used during the ensemble
        processing.

        It generates the tfrecord file containing the Examples for each TCE in
        this shard. The tfrecord file will then be used in Tensorflow
        processing.

        This method will be called in parallel, each execution in a different
        process using the multiprocessing lib, for each shard defined in the
        `generate_input` method, up to a maximum number of parallel processes
        also defined at `generate_input`.

        Parameters
        ----------
        tce_table: DataFrame
            Data frame containing the TCE information. It must contain the
            following columns:
                tce_period
                tce_duration
                tce_time0bk
                av_training_set
                kepid
        file_name: str
            Path of the shard file that is going to be generated by this run.
        kepler_dir: str
            Path to the directory where the lightcurves are stored.
        """
        process_name = multiprocessing.current_process().name
        shard_name = os.path.basename(file_name)
        shard_size = len(tce_table)
        print(f"{process_name}: Processing {str(shard_size)} items in shard {shard_name}")  # noqa E501

        with tf.python_io.TFRecordWriter(file_name) as writer:
            num_processed = 0
            for _, tce in tce_table.iterrows():
                print("Prosseing id %s", tce)

                try:
                    example = self._process_tce(tce, kepler_dir)

                    # Check if the example was correctly generated
                    if example is not None:

                        # Checks if the example contains NaN values, which will
                        # cause an ErrorTensor is NaN error during the training
                        test_local = np.isnan(example.features.feature.get("local_view").float_list.value).any()  # noqa E501
                        test_global = np.isnan(example.features.feature.get("global_view").float_list.value).any()  # noqa E501

                        if test_global or test_local:
                            # If there was a NaN value, clears the cache for
                            # this lightcurve and process it againg
                            file = os.path.join(self.cache_dir, str(tce['kepid']))  # noqa E501
                            os.rename(file, file+"_old")
                            example = self._process_tce(tce, kepler_dir)

                            # Then repeat the test
                            test_local = np.isnan(example.features.feature.get("local_view").float_list.value).any()  # noqa E501
                            test_global = np.isnan(example.features.feature.get("global_view").float_list.value).any()  # noqa E501
                            if test_global or test_local:
                                # If the error persists, remove this TCE from
                                # the execution, and write its information to a
                                # log file
                                erros = open("../tce_with_nan.txt","a+")  # noqa E501
                                erros.write(str(tce)+"\n")
                            else:
                                writer.write(example.SerializeToString())
                        else:
                            writer.write(example.SerializeToString())

                    num_processed += 1
                    if not num_processed % 10:
                        print(f"{process_name}: Processed {str(num_processed)}/{str(shard_size)} items in shard {shard_name}.")  # noqa E501
                except Exception as e:
                    print(f"{process_name}: Error.")
                    print(str(e))

        print(f"{process_name}: Wrote {str(shard_size)} items in shard {shard_name}.")  # noqa E501

    def generate_input(self, tce_table: DataFrame, num_train_shards: int):  # noqa E501
        """
        Reimplementation of the `main` function of the original
        generate_input_records.py module adjusted to our necessities.

        It splits the input TCE DataFrame in training and validation sets, then
        further splits the training set into shards and runs the processing of
        each shard in parallel through the `_process_file_shard` method.

        Parameters
        ----------
        train: bool
            Flag to indicate if this execution is a training or testing run.
            Kept for compatibility.
        tce_table: DataFrame
            Data frame containing the TCE information. It must contain the
            following columns:
                tce_period
                tce_duration
                tce_time0bk
                av_training_set
                kepid
        num_train_shards: int
            Total number of shards to be created.
        """
        os.mkdir(self.tfrecord_dir)

        tce_table["tce_duration"] /= 24  # Convert hours to days.

        num_tces = len(tce_table)
        print(f"Read TCE CSV file with {str(num_tces)} rows.")

        # Splits the training and validation sets
        x_train, x_val = train_test_split(tce_table, test_size=0.3)

        print(f"Partitioned {str(num_tces)} TCEs into training ({str(len(x_train))}) and validation ({str( len(x_val))})")  # noqa E501

        # Further split training TCEs into file shards.
        file_shards = []  # List of (tce_table_shard, file_name).
        boundaries = np.linspace(0, len(x_train), num_train_shards + 1).astype(np.int)  # noqa E501
        for i in range(num_train_shards):
            start = boundaries[i]
            end = boundaries[i + 1]
            filename = os.path.join(
                self.tfrecord_dir,
                "train-{:05d}-of-{:05d}".format(i, num_train_shards)
            )
            file_shards.append((x_train[start:end], filename, self.data_dir))

        # Validation and test sets each have a single shard.
        val_filename = os.path.join(self.tfrecord_dir, "val-00000-of-00001")
        file_shards.append((x_val, val_filename, self.data_dir))
        num_file_shards = len(file_shards)

        # Launch subprocesses for the file shards.
        num_processes = min(num_file_shards, self.num_worker_processes)
        print(f"Launching {str(num_processes)} subprocesses for {str(num_file_shards)} total file shards.")  # noqa E501

        pool = multiprocessing.Pool(processes=num_processes)
        async_results = [
            pool.apply_async(self._process_file_shard, file_shard)
            for file_shard in file_shards
        ]
        pool.close()

        for async_result in async_results:
            async_result.get()

        print(f"Finished processing {str(num_file_shards)} total file shards.")

    def process_tce_predict(self,
                            feature_config: dict,
                            kepler_id: str,
                            tce_period: float,
                            tce_time0bk: float,
                            tce_duration: float):
        """
        Process a TCE individually for prediction.

        Parameters
        ----------
        feature_config: dict
            Dictionary with the feature configuration stating which views,
            global view and local view, should be created.
        kepler_id: str
            Id of the KOI associated with the TCE, it is the id used to
            retrieve the lightcurve files.
        tce_period: float
            Transit period of this TCE.
        tce_time0bk: float
            Julian date of the midle point of this TCE's first transit detected
            on this lightcurve
        tce_duration: float
            Duration of the TCE transit event.
        Returns
        -------
        features: dict
            Dictionary containing the features (global and local views)
            in np.array format, as required in the feature_config input.
        """
        ex = self._process_tce(
            tce={
                    "tce_period": tce_period,
                    "tce_duration": tce_duration,
                    "tce_time0bk": tce_time0bk,
                    "av_training_set": None,
                    "kepid": kepler_id
            },
            kepler_dir=self.data_dir
        )

        features = {}

        if "global_view" in feature_config:
            global_view = np.array((ex.features.feature["global_view"]).float_list.value)  # noqa E501
            features["global_view"] = np.expand_dims(global_view, 0)

        if "local_view" in feature_config:
            local_view = np.array((ex.features.feature["local_view"]).float_list.value)  # noqa E501
            features["local_view"] = np.expand_dims(local_view, 0)

        return features
